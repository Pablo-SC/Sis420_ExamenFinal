{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "## SIS 420                           ##\n",
        "## Alumno: Sanchez Calvimontes Pablo ##\n",
        "## Carrera: Ingenieria de Sistemas   ##\n",
        "#######################################\n",
        "\n",
        "# se uso el dataset de:\n",
        "# https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification\n",
        "\n",
        "# este data set es usado para clasificar la salud fetal para prevenir la mortalidad infantil y materna.\n",
        "\n",
        "# el problema con este data set esque tiene pocos datos asi que primero se creo un dataset sintetico\n",
        "# para lograr una mejor prediccion del modelo\n",
        "\n",
        "# el data set tiene 22 columnas\n",
        "# baseline value\n",
        "# accelerations\n",
        "# fetal_movement\n",
        "# uterine_contractions\n",
        "# light_decelerations\n",
        "# severe_decelerations\n",
        "# prolongued_decelerations\n",
        "# abnormal_short_term_variability\n",
        "# mean_value_of_short_term_variability\n",
        "# percentage_of_time_with_abnormal_long_term_variability\n",
        "# mean_value_of_long_term_variability\n",
        "# histogram_width\n",
        "# histogram_min\n",
        "# histogram_max\n",
        "# histogram_number_of_peaks\n",
        "# histogram_number_of_zeroes\n",
        "# histogram_mode\n",
        "# histogram_mean\n",
        "# histogram_median\n",
        "# histogram_variance\n",
        "# histogram_tendency\n",
        "#-------------\n",
        "# LA COLUMNA Y (22) ES  :fetal_health\n",
        "\n",
        "\n",
        "# se realizaron muchas pruebas para obtener una funcion de perdida lo mas minima posible\n",
        "# los resultados se encuntran abajo\n",
        "# pero el mejkor resultado tommo 47 minutos aproximandamente\n",
        "\n",
        "#########################\n",
        "# con 500 neuronas      #\n",
        "# 100 epoch             #\n",
        "# 3 capas ocultas       #\n",
        "#########################\n",
        "\n",
        "# se uso 22000 datos para el entrenamiento y el restante se uso para el testeo del modelo"
      ],
      "metadata": {
        "id": "oAiA3FEeDk-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5-pOt1PznUQ"
      },
      "source": [
        "# Perceptrón Multicapa para Clasificacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6rRpxkTznUW"
      },
      "source": [
        "## MLP y Capas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsZIOmprznUW"
      },
      "source": [
        "Vamos a empezar definiendo nuestra clase `MLP`, esta clase estará formada por una lista de capas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-10T13:13:12.785890Z",
          "start_time": "2020-08-10T13:13:12.775889Z"
        },
        "id": "M6cf9PewznUW"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    def __init__(self, layers):\n",
        "        # el MLP es una lista de capas\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # calculamos la salida del modelo aplicando\n",
        "        # cada capa de manera secuencial\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-10T13:13:13.130767Z",
          "start_time": "2020-08-10T13:13:13.123088Z"
        },
        "id": "6aQ1UR1eznUX"
      },
      "outputs": [],
      "source": [
        "class Layer():\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "        self.grads = []\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # por defecto, devolver los inputs\n",
        "        # cada capa hará algo diferente aquí\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad):\n",
        "        # cada capa, calculará sus gradientes\n",
        "        # y los devolverá para las capas siguientes\n",
        "        return grad\n",
        "\n",
        "    def update(self, params):\n",
        "        # si hay parámetros, los actualizaremos\n",
        "        # con lo que nos de el optimizer\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foANpO11znUX"
      },
      "source": [
        "Ahora podemos definir las diferentes capas que utilizaremos. Hasta ahora sólo hemos visto la capa lineal y diferentes funciones de activación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-10T13:13:13.413081Z",
          "start_time": "2020-08-10T13:13:13.396082Z"
        },
        "id": "Fpo8MQ1UznUX"
      },
      "outputs": [],
      "source": [
        "class Linear(Layer):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        # pesos de la capa\n",
        "        self.w = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(d_in+d_out)),\n",
        "                                  size=(d_in, d_out))\n",
        "        self.b = np.zeros(d_out)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        self.params = [self.w, self.b]\n",
        "        # salida del preceptrón\n",
        "        return np.dot(x, self.w) + self.b\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        # gradientes para la capa siguiente (BACKPROP)\n",
        "        grad = np.dot(grad_output, self.w.T)\n",
        "        self.grad_w = np.dot(self.x.T, grad_output)\n",
        "        # gradientes para actualizar pesos\n",
        "        self.grad_b = grad_output.mean(axis=0)*self.x.shape[0]\n",
        "        self.grads = [self.grad_w, self.grad_b]\n",
        "        return grad\n",
        "\n",
        "    def update(self, params):\n",
        "        self.w, self.b = params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-10T13:13:13.553974Z",
          "start_time": "2020-08-10T13:13:13.534217Z"
        },
        "id": "NB1fZIm2znUY"
      },
      "outputs": [],
      "source": [
        "class ReLU(Layer):\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad = self.x > 0\n",
        "        return grad_output*grad\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "class Sigmoid(Layer):\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        return sigmoid(x)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad = sigmoid(self.x)*(1 - sigmoid(self.x))\n",
        "        return grad_output*grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNGcN0GCznUY"
      },
      "source": [
        "## Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-10T13:13:13.980603Z",
          "start_time": "2020-08-10T13:13:13.975081Z"
        },
        "id": "d1Q-AC5sznUY"
      },
      "outputs": [],
      "source": [
        "class SGD():\n",
        "    def __init__(self, net, lr):\n",
        "        self.net = net\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self):\n",
        "        for layer in self.net.layers:\n",
        "            layer.update([\n",
        "                params - self.lr*grads\n",
        "                for params, grads in zip(layer.params, layer.grads)\n",
        "            ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_l4DnBfznUY"
      },
      "source": [
        "## Funciones de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-10T13:13:14.563035Z",
          "start_time": "2020-08-10T13:13:14.545038Z"
        },
        "id": "QVXFoULcznUY"
      },
      "outputs": [],
      "source": [
        "class Loss():\n",
        "    def __init__(self, net):\n",
        "        self.net = net\n",
        "\n",
        "    def backward(self):\n",
        "        # derivada de la loss function con respecto\n",
        "        # a la salida del MLP\n",
        "        grad = self.grad_loss()\n",
        "        # BACKPROPAGATION\n",
        "        for layer in reversed(self.net.layers):\n",
        "            grad = layer.backward(grad)\n",
        "\n",
        "\n",
        "class CrossEntropy(Loss):\n",
        "    def __call__(self, output, target):\n",
        "        self.output, self.target = output, target\n",
        "        logits = output[np.arange(len(output)), target.astype(int)]\n",
        "        loss = - logits + np.log(np.sum(np.exp(output), axis=-1))\n",
        "        loss = loss.mean()\n",
        "        return loss\n",
        "\n",
        "    def grad_loss(self):\n",
        "        answers = np.zeros_like(self.output)\n",
        "        answers[np.arange(len(self.output)), self.target.astype(int)] = 1\n",
        "        return (- answers + softmax(self.output)) / self.output.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Qsocn0znUZ"
      },
      "source": [
        "## Implementación"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VByrjlgW08Zy",
        "outputId": "0f38ca20-427c-4733-f760-4f490ab68605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/EXAMEN_FINAL_SanchezPablo/ej2/Datasets/20k_datosSinteticos.csv', delimiter=',', skiprows=1)\n",
        "data = data.to_numpy()"
      ],
      "metadata": {
        "id": "eR9j_KLV1AQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[:22000 ,:21]\n",
        "Y = data[:22000, 21]\n",
        "\n",
        "# normalización datos\n",
        "X_mean, X_std = X.mean(axis=0), X.std(axis=0)\n",
        "X_norm = (X - X_mean) / X_std\n",
        "\n",
        "X.shape, Y.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jttAC_H31F_Y",
        "outputId": "6d0c976a-421f-4a56-9519-87d5054820ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((22000, 21), (22000,))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0E3NlCJznUi"
      },
      "source": [
        "### Clasificación Multiclase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-10T13:16:59.934417Z",
          "start_time": "2020-08-10T13:16:59.511295Z"
        },
        "id": "FH7tnUJiznUi",
        "outputId": "f9497b66-94e9-4cb4-f7eb-155fb518c173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 0.6245\n",
            "Epoch 20/100, Loss: 0.5861\n",
            "Epoch 30/100, Loss: 0.5104\n",
            "Epoch 40/100, Loss: 0.4285\n",
            "Epoch 50/100, Loss: 0.3617\n",
            "Epoch 60/100, Loss: 0.3107\n",
            "Epoch 70/100, Loss: 0.2728\n",
            "Epoch 80/100, Loss: 0.2417\n",
            "Epoch 90/100, Loss: 0.2165\n",
            "Epoch 100/100, Loss: 0.1955\n"
          ]
        }
      ],
      "source": [
        "D_in, H, D_out = 21, 500, 4\n",
        "mlp = MLP([\n",
        "    Linear(D_in, H),\n",
        "    ReLU(),\n",
        "    Linear(H, H),\n",
        "    ReLU(),\n",
        "    Linear(H, H),\n",
        "    ReLU(),\n",
        "    Linear(H, H),\n",
        "    ReLU(),\n",
        "    Linear(H, D_out)\n",
        "])\n",
        "\n",
        "optimizer = SGD(mlp, lr=0.02)\n",
        "loss = CrossEntropy(mlp)\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 10\n",
        "\n",
        "batches = len(X) // batch_size\n",
        "log_each = 10\n",
        "l = []\n",
        "for e in range(1,epochs+1):\n",
        "    _l = []\n",
        "    for b in range(batches):\n",
        "        x = X_norm[b*batch_size:(b+1)*batch_size]\n",
        "        y = Y[b*batch_size:(b+1)*batch_size]\n",
        "        y_pred = mlp(x)\n",
        "        _l.append(loss(y_pred, y))\n",
        "        loss.backward()\n",
        "        optimizer.update()\n",
        "    l.append(np.mean(_l))\n",
        "    if not e % log_each:\n",
        "        print(f'Epoch {e}/{epochs}, Loss: {np.mean(l):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#array de prueba\n",
        "X_test = X[20000:, :].copy()\n",
        "\n",
        "#Normalizar datos de prueba si es necesario\n",
        "X_test_norm = (X_test - X_mean) / X_std\n",
        "\n",
        "# Pasa datos de prueba a trabes del modelo para obtener las predicciones\n",
        "y_pred_test = mlp(X_test_norm)\n",
        "\n",
        "#convierte las predicciones a clases\n",
        "prediccion = np.argmax(y_pred_test, axis=1)\n",
        "\n",
        "# puedes imprimir las predicciones para verificar resultados\n",
        "print(\"Predicciones del modelo: \")\n",
        "print(prediccion)\n",
        "print(\"Valores Realess: \")\n",
        "print(Y[20000:])\n",
        "\n",
        "#calcula el porcentaje de relacion entre las predicciones y los valores reales\n",
        "total_ejemplos = len(prediccion)\n",
        "correlacion = np.sum(prediccion == Y[20000: ])\n",
        "porcentaje = (correlacion / total_ejemplos) * 100\n",
        "\n",
        "#imprime el porcentaje de relaccion\n",
        "print(\"Porcentaje de relacion: \")\n",
        "print(f\"{porcentaje:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR_sXVT1CoF4",
        "outputId": "1cdbbcdc-226b-4d55-d203-513523e3a882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones del modelo: \n",
            "[1 2 1 ... 1 3 1]\n",
            "Valores Realess: \n",
            "[1. 2. 1. ... 1. 3. 1.]\n",
            "Porcentaje de relacion: \n",
            "99.95%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}